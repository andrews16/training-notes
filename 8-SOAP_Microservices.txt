
	   SOAP, Netflix Stack, Microservices, Docker
Contents:
* REST
* SOAP
	* Creating SOAP Server
	* Contract First
	* SOAP Requests from Java
	* SOAP Fault
* Microservices / Getting Started
* Zuul Filters
* Netflix Stack Overview
	* Eureka
	* Zuul
	* Hystrix 
* JSR 303 Validation
* Feign
* Hystrix
	* Using Hystrix
* Configuration Server
Work in progress chapters:
* Containerization
* Docker
	* Docker Swarm
	* DockerHub
* Orchestration


===================================================================
		  * REST (Other topics)
===================================================================



===================================================================
			* SOAP
===================================================================

SOAP - Another way systems can communicate. 
	- Not REST. 
	- Simple object access protocol
	- Strictly XML based.
	- Older protocol than REST.

REST was HTTP and HTTPS only. Based in HTTP
SOAP can is usable on many protocols(Not limited to HTTP/HTTPS)
	- Can't rely on GET/POST/PUT verbs!
	- Must be built into system.
	- Exceptions must be built in via MESSAGES not error codes
	-> SOAP has to be XML
	- SSH doesnt use HTTP. SOAP can be used for this.
	- Many legacy systems use SOAP, so you must know it.
	- SOAP is good if you need mutiple protocols to access it

==> Contract-based:
	- Application has a contract: wsdl 
	(web service definition language)
	  -- Catalog that stipulates exactly how to operate with
	      the applicatoin.
	  -- XML document
	  -- REST's contract has, wadl but it isn't mandatory
	-- Can be generated via tools.
==> Tools:
	- Single language is old, there are many tools, for example
	 we can generate from object to wsdl or the other way:
		Object --> wsdl
		wsdl --> Objects
	- Dev would probably want to do Object -> wsdl
	- Client would want to use wsdl -> objects

Spring boot has SOAP tools.
Neumonic device to remember SOAP features: TECMAPS

	      	       SOAP			 REST
Tools 			Yes		|	Minimal
		(Like apache CFX)	|	
Exception Handling	Built-in	|    HTTP status codes
Contract		Yes, wsdl	|	minimal, wadl
Message 	    Yes, structure3d	|       Not really
Atomicity      Built-in transactions.	|      No guarentee
Protocol	Hadles many diff kinds	|	Only HTTP/HTTPS
Security	Built-in		| 	use HTTPS


Greatest benefits / consideration: 	
	- multiple protocols and built-in security.

 ~~~~~~~~~~~~~~~~~~ * Creating a SOAP Server ~~~~~~~~~~~~~~~~~~~~~~
The following example will build object from an XML Schema and then
use tools to build a wsdl to represent the project.

First, get get POM files & update.

- Create file SuperHero.xsd in source/main/resources
	-- It starts up looking like an empty table
	-- Click source tab to get to actual code.
Paste this:
<?xml version="1.0" encoding="UTF-8"?>

<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"
    targetNamespace="http://www.example.org/SuperHero"
    xmlns:tns="http://www.example.org/SuperHero"
    elementFormDefault="qualified">



</xs:schema>

- The tns, of course, is fake.
- Start by defining our types inside xs:schema tag.
---- xs:schema is the root tag for the Xml Schema documents
- xs means we're using that labelled namespace as seen in the 
	code above.
== Creating an object:
  - Complex type is an object, and objects contain elements

<xs:complexType name="SuperHero">
  <xs:sequence>
     <xs:element name="name" type="tns:string" />
  </xs:sequence>
</complexType>

== Creating an Enum
  - xs:simpleType is the definition of what it /is/ 
  - base type restriction says what type the literal value can be.
	(in this case, an enum)
<xs:simpleType name="superPower>
   <xs:restriction base="tns:string">
      <xs:enumeration value="Flight">
   </xs:restriction>
</xs:simpleType>

== Defining request and response (getters and setters, basically)
- Define what the request sh'd look like when someone asks for hero
<xs:element name="GetHeroRequest">
   <xs:complexType>
     <xs:sequence>
	<xs:element name="id" type="tns:int">
     </xs:sequence>
   </xs:complexType>
</xs:element>

- Define what the response should look like when a hero is returned
<xs:element name="GetHeroResponse">
   <xs:complexType>
     <xs:sequence>
	<xs:element name="SuperHero" type="tns:SuperHero">
     </xs:sequence>
   </xs:complexType>
</xs:element>

== Now add that one other section into the POM and update:
-- The schema directory points to the xsd schema file and tells the 
   program where to put the resulting file.

<build>

   <plugins>

      <plugin>
 
         <groupId>org.springframework.boot</groupId>
			            <artifactId>spring-boot-maven-plugin</artifactId>

      </plugin>

      <plugin>

	  <groupId>org.codehaus.mojo</groupId>
				
            <artifactId>jaxb2-maven-plugin</artifactId>

            <version>1.6</version>
	</plugin>
<executions>
   <execution>
	<id>xjc</id>
	<goals>
	
	  <goal>xjc</goal>

	</goals>

	<configuration>
		
	  <schemaDirectory>
		${project.basedir}/src/main/resources/
	  </schemaDirectory>

	<outputDirectory>
		${project.basedir}/src/main/java\
	</outputDirectory>
			

	<packageName>com.revature.models</packageName>

	<clearOutputDir>false</clearOutputDir>
		
	<schemaFiles>SuperHero.xsd</schemaFiles>

	</configuration>
</execution>
</executions>
			
</plugin>

</plugins>
</build>


-- Once it builds successfully, we will have an model for hte object
-- Create repository (in this example, just stores the information in memory)
@PostConstruct is the first method that runs after the bean is constructed.

-> Create WebServiceConfig class
@EnableWs annotation at the top. for WebService
    - This config files gets the mapping and whatnot
    - Defines the beans
    - wsdl related objectlocation URI
    - Port handler 
    - and application 

--> Create class ENDPOINT in com.revature.endpoints
	- superhero endpoint
	- Works like a controller, but for SOAP
	- Maps request to actual functionality
	- @Endpoint annotation

	- Needs a NAMESPACE URL for the mapping
	Autowire superhero repo

/**
 * @PayloadRoot - similar to @RequestMapping
 * @RequestPayload - similar to @RequestBody
 * @ResponsePayload - similar to @ResponseBody
 * @return
*/

@PayloadRoot(namespace = NAMESPACE_URI, localPart = "getHeroRequest")
@ResponsePayload
public GetHeroResponse getSuperHero(@RequestPayload GetHeroRequest request) {
	GetHeroResponse response = new GetHeroResponse();
	response.setSuperHero(superHeroRepo.getSuperHero(request.getName()));
	
	return response;
}


************* PANEL WILL ASK ABOUT THIS ***********


IN THAT xsd file, you defined TYPES for gethero request and response, not methods.
Anyone who wnats to comminicate with the api can find thoswe type difinition directly in the wsdl file
==>
	

Now we can test the server and get request back by using the 
request format and an HTTP POST.
Root tag: Envelope.
==> Structure:
 	 Envelope
 	     |--Header	[meta data]
 	     |--Body
		   |-- Request Name
		 	   | -- Parameters

==> POST Body:
<soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/"
                  xmlns:tns="http://www.example.org/SuperHero">

    <!-- Send request to: localhost:8080/ws/  -->

   <soapenv:Header/>

   <soapenv:Body>

      <tns:getHeroRequest>

         <tns:name>humanTorch</tns:name>

      </tns:getHeroRequest>

   </soapenv:Body>

</soapenv:Envelope>


-- The tns stuff is actually important too. 
   If you change it you wont get anything back!

-- Namespace maps out the handler for the endpoint config.
-- If the target namespace doesn't match, it cannot handle it. 

==> TO RETRIEVE the wsdl
  -- Use the bean name as the mapping.
	http://localhost:8080/ws/superheroes.wsdl

WSDL: Tag Structure: (All are prefixed with wsdl:)
definitions
   |-- types
	|-- schema
	     |-- [other schema tags. element -> complextype
		  ---> 


~~~~~~~~~~~~~~~~~~~~~ * Contract First ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
POM file:
Dependencies:
- Spring boot
- spring-boot-starter
- spring-boot-ws-core
Plug-ins:
- org.springframework.boot (spring boot maven plugin)
- morg.jvnet.jaxb2.maven2 (maven-jaxb2-plugin)
	-

- Within the definition of the jaxb2 plugin, the configuration:
<configuration>
 <schemaLanguage>WSDL</schemaLanguage>
  <generatePackage>com.revature.models.generated</generatePackage>
  <generateDirectory>
    ${project.build.sourceDirectory}
  </generateDirectory>
  <schemas>
    <schema>
	<url>http://localhost:8080/ws/superheroes.wsdl</url>
    </schema>
  </schemas>
<configuration>

Locates the wsdl and is set (via <execution>) to generate classes
The URL could be online or local.
The wsdl is converted to objects and methods automatically!


	 ~~~~~~~~~~ *  SOAP Requests from Java ~~~~~~~~~~
- Now you can also consume an external SOAP resources
- You needed to take the wsdl and transform it to objects so you know
  how the dever from which you desire information is set up, but you
  don't have their data! Once you have the classes set up above, you
  now need to get information from the other server.


First, set up a ResourceClient class of its own. 
 --- THIS class extends WebServiceGatewaySupport
 --- Here, define the methods you'll be calling on the other server
   - Example:
  public GetHeroResponse getHero(String name) {
	GetHeroRequest request = new GetHeroRequest();
	request.setName(name);
      GetHeroResponse response=(GetHeroResponse)getWebServiceTemplate
		.marshalSendAndRecieve("URL-FOR-ENDPOINT", request,
			new SoapActionCallback("targetnamespace"));
  	return response;
  }


Next, set up config bean to marshall (transform) the data.
	- The marshaller has a setContextPath for local files.
	- This tells the application what the requests and responses
	should look like and how they shall be set up.
- the Client shall have a setDefautltUri to the endpoint
  of the other sever, as well as setting the marshaller and an
  unmarshaller.


- In the class example, we set up the application in such a way that 
  the Spring Boot client application runs, but does not actually 
  start up the Tomcat server. It just runs and has a bean which 
  calls the other application via SOAP(Simple Object Access Protocol)


  ~~~~~~~~~~~~~~~~~~~ * SOAP Fault ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
https://www.ibm.com/support/knowledgecenter/en/SSGMCP_5.3.0/com.ibm.cics.ts.webservices.doc/concepts/soap/dfhws_fault.html

- SOAP <Fault> element carries error and status info in messages
-
<SOAP-ENV:Fault xmlns="">
   <faultcode>SOAP-ENV:Server</faultcode>
   <faultstring>Conversion to SOAP failed</faultstring>
      <detail>
         <CICSFault xmlns="http://www.ibm.com/software/htp/cics/WSFault">
          DFHPI1008 25/01/2010 14:16:50 IYCWZCFU 00340 XML
          generation failed because of incorrect input 
          (CONTAINER_NOT_FOUND container name) for WEBSERVICE 
          servicename. 
          </CICSFault> 
      </detail> 
</SOAP-ENV:Fault>

 ==================================================================
		* Microservices / Getting Started
 ==================================================================

Services may or may not have a front end.

Monolithic server:
 - A server that connects to a DB with no front end.
 - SPF: Single Point of Failure - Any place in application structure
	where failure would cause a cascading effect and crash the
	entire application
 - If something is wrong in monolithic server, it'll put down the 
   entire application.

	.---------.	    __
	| Server  | --->  ( DB )
	|	  | <---  ( __ )
	'---------'

Microservies: 
 - Instead microservices many small services with their own DBs. 
 - One main server connects to those smaller ones.
	- If a small server fails, the whole system wont go down

		     .--> [Service A] <--> (DB A)
	.---------.<-'	    
	| Main    | <---> [Service B] <--> (DB B)
	| Server  |  
	'---------' <---> [Service C] <--> (DB C)

 - Goal : Eliminate all single points of failure.
 - Also allows for load balancing as a developer.
 - Issue: If A has many-to-many relationship with B,
	 how do we enfirce referential integrity when our
	 databases are separate?
 - Move from ACID system to BASE.
	--> Basically Available 
	--> Soft state
	--> Eventual consistency

 --> Eventual Concistency:
  -- Guaruntees liveness:
    Concurrency systems need to make progress, despite multiple 
    parts of the program are out of sync.
	- Parts of the program may have to "take turns"
  -- Says that eventually -- after the final update - all pieces 	    of information will be consistent. Data may be overriten -
    typically with a "last-writer-wins" approach. 

Tools:
1. Discovery Service --> Eureka (Netflix's open source tech)
  - When server comes online, it sends message to Discovery server
  - Occassionally Discovery Service sends "heartbeat"
	- Checks if other servers are online.
	- Server wants to catch it BEFORE the user do (~20 seconds)

2. Gateway Service --> Zuul (Netflix's open source tech)
  - Single point of entry for requests into the system.
  - Doesn't matter where other servers are because USERS never go 
    directly to them.
  - Requests from outside go to gateway service to be handled. It
 must figure out which service to delegate it to. It has an idea, but
 doesn't know where the serivce is located, so it sends the request
 to the discovery service to figure out where it should go. Discovery
 service tells gateway serivice where the desired service is, and
 then the gateway sends it off to the right location.
	This is basically a front controller pattern.


1. Creating discovery Service
	- add pom dependencies
	- Create application.yml 

-By default Eureka itself will try to register with Eureka. This will
 cause constant errors in our starter project because there is no
 other Eureka instance to register with, so we will disable that
 funcionality
- Application.java
	@Spring boot...
	@EnableEurekaServer annotation

Create Gateway service with Zuul dependency.
--application .yml:
spring:
  application:
    name: Zuul

- Application.java
	@Spring...
	@EnableZuulProxy annotation

Create your service. 
	- does not need eureka core...
	- in application.yml, port:0 should give it a random port #

	@SpringBootApplication
	//@EnableEurekaClient
	@EnableDiscoveryClient 
	// More generic way to register with a discovery server

===================================================================
			* Zuul Filter
===================================================================

- Filters: Capable of performing range of actions during routing of
	HTTP requests and responses.
- Key Characteristics of a filter:
  -- Type : Defines stage during routing what applied
  -- Execution Order : Order of execution across filters
  -- Criteria : Condition to which the filter is applied
  -- Action : What the filter does upon execution

==> Filter Types:
  - PRE  : Filters execute before routing to origin
	- Authentication, choose server origin, log debug info
	- Can accept/request request right away here.
  - ROUTING : Handle routing request to origin. 
	- This is where HTTP request is built & sent with Ribbon 
  - POST : Filter to execute AFTER request routed to origin.
	- EX: Add standard HTTP headers, gather statistics
  - ERROR : Executes when errors occur during other phase. 
	- Centralizes error-handling logic
  - Custom filters are supported as well.

==> Behavior
- The same behavior (filtering) is available in servlets and spring 
  MVC at the front controller level. 
- Zuul filters are an extension of that behavior; 
  Behavior is implemented with Zuul.
- application.yml file can be configured to filter routes as well
  + Zuul can manage routes & forwarding via configuration
https://cloud.spring.io/spring-cloud-netflix/multi/multi__router_and_filter_zuul.html


==> To use, extend the ZuulFilter abstract class.
 -- Make a bean (@Component or other config) and extend ZuulFilter
	It requires overrides of some methods.

* You can get the HttpRequest/Response in zuul filters
==> Methods:
- public boolean shouldFilter() { } 
   - Predicate to return true/false if that filter should run.
   - Example (Will only filter request if it has no cookies)
   @Override
   public boolean shouldFilter() {
	RequestContext context = RequestContext.getCurrentContext();
	HttpServletRequest request = context.getRequest();
	if (request.getCookies().length == 0) {
		return true;
	}
	return false;
   }

- public Object run() throws ZuulException{ } 
  - actual filter behavior (can return an object, some 
    arbirarty artifact, or it can be null)
  - Example (Adds a cookie)
  public Object run() throws ZuulException {
      RequestContext context = RequestContext.getCurrentContext();
      HttpServletResponse response = context.getResponse();
      Cookie cookie = new Cookie("Filter-cookie", "true");
      response.addCookie(cookie);
      return null;
  }

- public String filterType() { }
  - defines the type of the filter. 
  - Return a string with one of the filters as listed above.
 
- public int filterOrder() { }
  - Returns integer, for if you need to set up precedence (order)

==> Overall: 
- Straightforward implementation. 
- Can get request/response objects in run phase to be manipulated
  They can be altered here.
- Exceptions can be handled. ect. 

==> See :
https://github.com/Netflix/zuul/wiki/how-it-works

==> Routing Filters :
Routing filters may be applied during the process of routing to the 
filters. For this applicaiton, we dont need to create routing
filters, but it's possible. Routing filters are configured in
 application.yml (or config server)
Origin server is where request actually goes.
After request goes to the origin, we're not dealing with a response.
If an error occurs, after an error filter runs, it is delegated to
 the post filters. Then its sent back to the client. 

- May be useful for defining where behavious should happen. 


====================================================================
		* Netflix Stack overview
====================================================================

 ~~~~~~~~~~~~~~~~~~~~~~~~ * Eureka ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- @EnableEurekaServer / @EnableDiscoveryServer
	- @EnableEurekaClient
- Discovery service - keeps track of servers locations and status
- Port 8761
- Analogout to an INTERNAL DNS (domain name service)
- Primary purpose: load balancing within a single region.
- Used for server traffic that is not to be exposed to the public

- Non-java clients run a "side car" (java-embedded eureka server) 
  to handle service registration & heartbeats, then use REST 
  endpoints supported by Eureka client
- Resilinency: Can handle failure of one or all Eureka servers due to
  registry caching information in services.

 ~~~~~~~~~~~~~~~~~~~~~~~~ * Zuul ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- @EnableZuulProxy
- Recieves request and forwards it to location of an avaiable server
- Manages server-side load balancing on instance/server/host level
- Uses Netflix Ribbon to look up instances of the service
	- Ribbon: internal process, provides load-balance algorithms
- Stateless service, provides resilliency to load-balancing outages 
	- You don't have to rely on external load balancer
- Port 8888

~~~~~~~~~~~~~~~~~~~~~~ * Hystrix ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- Latency & fault tolerance library -> to isolate points of failure
- Stop cascading falure, enable resillience in complex systems
- Latency: The state of existing, but not yet being developed or 
	manifested... The delay before a trasfer of data begins
	following an instruction for its transfer.
	- Delay between stimulus and response.
Main selling points:
   1. Latency & Fault Tolerance
	-- Stop cascading failures
	-- Fallbacks and graceful degredation
	-- Fail fast, rapid recovery
   2. Realtime Operations
	-- Monitors & configures changes
	-- Alerts/makes decisions/affects change/ fast results
   3. Concurrency
	-- Parallel execution (Thread safe)
	-- Concurrency-aware request caching
	-- Automated batching through request collapsing


====================================================================
		  * JSR 303 Validation
====================================================================
 - Related to Bean Validation.
 - Hibernate and Spring can use JSR303 annotations to validate beans.

 - Involves constraints which can be validated against.

Example - Set annotations above an object property:

 // Length is for lists and strings. this is treated as a string..
 @Length(min=10, max=10, message="ISBN values must be exactly 10  characters")
 private int isbn;

 @Min(1)
 private int pageCount;

 @NotNull
 private String title;

==> owasp.org has really good docs about this stuff. 
https://www.owasp.org/index.php/Bean_Validation_Cheat_Sheet#Pre-defined_Constraints

https://beanvalidation.org/1.0/spec/#constraintdeclarationvalidationprocess
====================================================================
		    * Feign
====================================================================
- Feign part of Spring Framework
==> Conceptual: 
- Cost/benefit relationship...
	- Cost of losing UP time vs cost of maintaining.
	- Most ot maintain is complexity. 

- We are going to give the book entity the ID for another entity
  rather than using hibernate Many-to-one relationship

-> Many to many needs some kind of relationship, and we can use a
 collection of primitive types and it will map to a junction table. 
     --> @Collection annotation, not @ManyToMany. <--
 ((See Jboss @ElementCollection annotations.))

==> Either way, we'll need information from other servers!
To send request from Java server to another server
- You can use RestTemplate(find old notes) without Spring.
- With Spring, use Spring Cloud Stater Feign.

-> Getting started:
	1. Add maven Feigns package to pom.
	2. Add @EnableFeignClients annotation to Application.java
	3. Create Client interface

- Client interface holds method /declarations/ with the desired
  mapping in the other server as required foreign Repository.
   -- When you call those methods, Spring translates the method
      declarations into requests, and sends them to the other server.
	-- The mapping and parameters need to be the same, but
	  you could get away with not knowing what the other server's
	  methods are actually named.

[Class Definition]
-Feign client - to use add @EnableFeignClient to application.java
-Feign classes are interfaces that are mapped to the other interface
 you want to contact and have abstract methods with the same signate
 use mapping as the other controller it is trying to contact.

-> This dependency introduced a single poitn a failure: 
If book service goes down, you can't use the part of author service.
-> Solution: Use latency/Fualt Tolerance library!

====================================================================
			* Hystrix
====================================================================
- Hystrix is a latency and fault tolerance library design to:
   -- isolate points of acess to remote systems, service, 
	and 3rd	party libraries
   -- Stop cascading failures

Hystrix is an example resillience in complex distriuted systems.
Failure is inevitable, but Hystrix is used to recover quickly and
make the failure seem less detrimental

-> Basically this helps to avoid cascading failure.
-> Prevent this from happening with Fault tolerance. 

   ***** Fault Tolerance is a HUGE concept in microservices *****
  In Netflix stack, Hysterix is the biggest took in fault tolerance.
 It provides a simple way to wrap code in fallback behavior, telling
  it what to do if exception is raised or a service is unavailable
 ******************************************************************


- If request isn't critical partial, partial info may be returned
- But other times, thats not the case.
=> Example: Amazon:
	Order Service ---> X Shipping Service
- Your order would go thru but it would never hit shipping service!! 
- That would be bad. This is not a good thing.
- We need to be sure everything /happens/
- Hystrix is tool for EVENTUAL CONSISTENCY.

- Messaging Queue: 
  -- Sits between services, and brokers their messages
  -- Stores message if one of the services is offline. 
	- Once the service turns back on, the messaging serice can 
	  send the message back out to messeging service.
	- Messaging service can confirm when the que has gone thru

  -- When service comes online, it sends it message, keeping a copy,
     until the next service tells it that it's fully resolved before
     letting go of the message.
- Messaging Queue is actually just another service. 

 ~~~~~~~~~~~~~~~~~~~~~~ * Using Hystrix ~~~~~~~~~~~~~~~~~~~~~~~~~~~
- The Feign client above is analogous to a foreign CONTROLLER.
- A Command class with Hystrix is analogous to a SERVICE class

1. Add @EnableCircuitBreaker annotation to Application.java
2. Create MyObjectCommand class in .commands package
3. Create 2 methods, one for attempting to use the Client, and 
   the other as a fallback incase the foreign server fails.
  --- Methods must have the same signature (arguments/return type)
4. Add @HystrixCommand annotation & properties:

  @HystrixCommand(vallback ="methodname")
  public void myMethod(arguments) {
	// Use Feign Client Here.
  } 

  public voic myMethodFallback(arguments) {
  }


 ~~~~~~~~~~~~~~~ * Circuit Breaker Design Pattern ~~~~~~~~~~~~~~~~~
- Hystrix uses the circuit breaker design pattern
- This is a pattern in qhich calls to remote software are wrapped in
  a protected function call in a circuit breaker object. 
- Protected function monitors for failure in the other server.
- If/when failure occurs, fallback fuction is triggered in place of 
  the other call.
	- The call to the supplier server *is never made* if the 
	  circuit breaker detects it is offline.

===================================================================
		     * Configuration Server
===================================================================
- Part of Spring Boot Cloud
- Config server tells application how to be configured
- Provides a centralized location for configurations for simplicity

- Configuration lives on a Git repository
- When the config server starts up, it is configured to look on git
  for configuration info. When new services come up, they register
  with the config server, and then the other services can start up.

- They are confiugred to fail /fast/. If a service can't look at the
 config server, it will just immediately stop. We don't want services
 to take up resources if they aren't working. They fail fast if
 config isn't avialable to them. 

- First start the config server, hten the discovery server. Then the
 other components can come in. They're start with the config server,
 ect. THeres a bit of latency, but we're able to centralize the
 configuration. This is more secure. Those working on particular
 services dont' need to see/manage config. Actually it hides the
 config from developers of the other/new services. 

		This is one of the ways to supply 
		   *Centralized Configuration*

1. Added Spring Cloud Config dependency


2. Create bootstrap.yml
- Config server should have the port 8888 and 
  spring.cloud.config.server.git.uri: Github Repo URL
	(But with the : and indentatiosn in yml form)

3. Change existing application's properties.yml file to bootstrap.yml
	(Each app's config only needs it's name)
-> Bootstrap happens way early in the lifecycle. Applications should
  have a bootstrap.yml file rather than an application.yml file.
Bootstrap.yaml is the first thing that happens when an application's configuration starts up. Later after starting up more, it'll have a 
hook to look at application.yaml. Apps needs to connect to the config 
server right away, and so if we try ot use application.yaml, it
happens too late in the configuration... So we must offer config in
bootstrap.yaml in order for the config server to provide
configuration that is needed.

4. The git repo shall contain a .yml file for each application, and
  the name of the .yml corresponds to the application's name it it's
  bootstrap.yml file. The other properties for each application will
  go in their yml in this folder.

4. Global configurations go in an application.yml file in the git

5. Services need a dependency (ex AUTHOR SERVICE and BOOK SERVICE) to
   org.springframework.cloud the spring-cloud-starter-config
   dependency. This'll tell it to look to 8888 for configurations.

-> Useful to conrol where the configuration details arre defined in one centralized location that we can manage. 


===================================================================
 			* Containerization
===================================================================
Messaging Queues
=> Snowflake server : 
- Maintainging application over time without records of patches... environment becomes more unique and harder to replicate. When things go wrong, you can't rollback anymore, and can't get help. 
- Server maintenence doesn't take many people and typically information isn't shared to the "new server guy" much.
- Should NOT design things like this.
=> Phoenix Server 
- HAS a PLAN for falling apart and stuff.


- Containerization is a new take on what is virtual server.
- Running virtual servers requires a lot of resources.
- Instead all wil operate in teh same OS, buut the environment will be specialized for the application.
- Container has the dependencies and environments and we interact with it through an interface.
- Container contains everything the application needs to run, and can be over to another server as needed.
- Pretty simple with Spring Boot - it creates jars.
- You define what the language and setting is on the container so the server can run it fine.

=> containerization is CENTRAL to microservices
- You don't want ot configure 3-4 servers to run the project, you just want the environment to be defined and possible

HOW TO:
Just install Docker.
Elastic beanstalk can do it with just the container and it can run it.
- Image: build a package of what the container should look like to create an image that we can rn it from. Image is a configuration of files and a configuration of commands to start it up. It's a blueprint for starting up the server & running it in that environment.

- TO DO THIS: Use the EC2. Run a container of the EC2.

curl - command line cmd to send (generally) http requests.

In docker:
applications operate/talk to eachother from different ports. 

First create a docker file by
creating a folder and putting your jar in there.
Create file named "Dockerfile" in that folder.

Number of commands to specify RTE of java application.
Java RTE is a JRE so we will run it in one.
Use keywork FROM to specify the runtime environment

#Set the environment in which the application will run with
#Our java rungs on the JRE so we should supply some JRE or JRK version

FROM openjdk:8-jdk-alpine

#Specified teh directory it worksi n
# Creates a directory structure within the containers environment
WORKDIR app/

#Copy or add file from our file structure into the containers file structure
COPY HelloDocker.jar app/

#Doesn't do anything but lets us know that we intend to expose port 80 on this image/container

#At the end, include commands to run to begin the application
ENTRYPOINT ["java", "-jar", "app/HelloDocker.jar"]


Save
Then start:
#	dockerhub username-v   v-- name   v--search all in this dir
docker build -t rclayandrews/hello-docker .
#           v--port, maps the port 80 here to server 8080 port
docker run -p 80:8080 rclayandrews/hello-docker

#ctrl+c to get out of console... This will shut down the application
# Run with -d instead to detach the view from the console.
docker run -p 80:8080 -d rclayandrews/hello-docker


# can login to docker with
docker login

#To stop the instance, just provide the first 3 keys in the hash identifier




Port entry is default port for HTTP is 80. 
so when you map 8080 to port 80 then all http requests will be forwarded to 8080.  req goes to container which sends it to 8080 and the app is listening for requests there.



Benefit : Containers are really light weight! They don't require much memory.


How to pass in environment variable when you run the application:


docker run -p 80:8080 -d -e "EXTRA=two hundred" rclayandrews/hello-docker

#List all running containers:
docker container ls


#remove image:
docker image rm rclayandrews/hello-docker

#And provide enrivonment variable in the configuration:
(like between the copy and the expose)
ENV EXTRA="some value"
     ^----- variable name in the code

# Additionally, we can override there ariables by passing varaibles during hte coker run command with the -e flag.


****************************************
QC will ask about the Docker files. 
Docker has pretty god documentation.

-> docker file says how the file should be set up. Docker build parses the file..

# Docker files MUST START WITH A FROM INSTRUCTION.

FROM <image> [alias]

# Can be any valid image, especially each to start by pullin an image from the public repositories... This is what we did with the JDK.
-> We can precees from with ARG, but its unnessecary....

ARG CODE_VERSION=latest
FROM openjdk:8 .......

RUN <command> is a shell form commant that is run in a shall, which is by defualt /bin/sh -c on Linux or cmd /S /C on windows

CMD can be used for starting the application up, siilat for the entry command.  Essentially this is what we do as the final step.
ENTRYPOINT can be used the same way
-> Main purpose is to provide defaults for an executing container. Defaults may or maynot include executables

LABEL >> metadata on image

EXPOSE --- informs docker that the container listens on the specified network ports at runtime. 
EXPOSE does not actually public the port, it functions as documentation between the person who builds the image and the person running the container oabout which ports are intended to be published.

Environment
ENV <key> <val>
ENV <ken>=<val>

ADD is like copy. It copies new files/dir /remote URLS from source and adds them to the filesystem at hte path destination.

COPY is slightly different from add in its rules, but works basically the same)

ENTRYPOINT allows yo uto configure a container that runs as an executable.

VOLUME instruction creats a mount point with the specified name and marks it as holding externally mounted volumnes form native hosts or other containers. The value can be a JSON array or play string with multiple arguments. 

If you need to write info that is saved nad save, you need to use attached volume sto make sure there is stoage OUTSIDE the container to write changes to.

USER - allows you to specify user or uid to allow permissions to run the image as.

WORKDIR - sets the workign directory for any run and cmd and entrypoint and copy and add that follow it in the dockerfile.

arg - for arguments. defines variables that the suer can pass at build-time to the builder with the docker build command using --build-arg <varname>=<value>


* QC will ask questiosnabout the docker file.
Panel will ask about command line stuff
How to create an image.

	docker built -t <tagname>/<entry-point> .



==================================================================
DockerHub
==================================================================
Pushing things to dockerhub.

IN instance, efirst LOGIN to docker:
	docker login
then its just like git...
	docker push rclayandrews/hello-docker

also can go 
	docker pull username/container


Docker makes it must more simple to deploy things.
Also can be used to start a stack.





** KNOW WORKFLOW of getting image ** 
** Know what docker swarm is **

===================================================================
Orchestration
==========================================
Dev ops side of mocroservice architecture

--Dev (notes)--
Discover S
Gate S
Book S
Author S
COnfig S

This is about how our resources are acquired to run all our stuff.
- Nodes start up and orchestration defines how these things hsould work.

SHould there be 2 book services? 2 Auther survers? more? less?

Docker Swarm allows us to say the machine the docker is run on is a machine in the swarm -- all of the service machines together.

# docker swarm init to start the system on your machine.
docker swarm init
# Initializes. image a bunch of machine do this.

# One machine says its the master and the others connect to it.
It tells all the other machine sabout eachother, adn then it becomes decntralized. 

- Then a service from each node can be deployed. IF one service goes down on a swarm node, we can let another swarm's service of that type run it instead.
If the master goes down, select another node as a master.
When a new master is selected , they can re delegate resources.

Docker swarm mangages these things.

We just tell it what the configuration and envronment is, and the swarm maintains itself. 

This will keep the aplication up. This orchectration is thre real heard of microservices architecture.

-> Kind of tricky with regular docker (without swarm)
Programs that do it:
 AWS Cloud Formation.
docker swarm
Kubernetes 

-> Will be asked conceptually about this. 
-> Benefit: MONEY! Orchestration supplies configuration and supplies resources and the software automatically manages hte application lifecycle as a while 
Behaivire: auto deploy docker images
config that allows them to talk to eachother even if we dont know hwere they are.
Failsafe - master node can be reassigned if it goes down.
Control environment
contorls config
prevents things from being lost
If one server goes down, start new one to maintain load balancing.

Can auto-increase size of conatiner/services

we are just using default sizes right now.

can do the same thing automaitcally when we configure orchestration - so it responds to the needs of users/application as a whole. 

* ** The final step in microservice architecture ** 














